v5.10.1 = Dashboard Surfacing + Firestore Mirrors for the v5.10.0 analytics.

ðŸŽ¯ v5.10.1 Goal

On top of v5.10.0:

Expose execution intelligence via helpers in dashboard/live_helpers.py:

get_symbol_score(symbol)

get_hourly_expectancy(symbol)

Add an â€œExecution Intelligenceâ€ section/tab in dashboard/app.py:

Symbol score + components

Hourly expectancy table (or simple pseudo-heatmap)

Mirror intel to Firestore so remote dashboards / alerts can consume:

publish_execution_intel(symbol, payload)

Executor hook to periodically publish for active symbols

Tests ensuring helpers and Firestore mirroring are wired correctly.

No behavior changes yet â€” still read-only.

ðŸŸ¦ Commit 1 â€” Live Helpers for Symbol Score & Hourly Expectancy

Commit message:

[v5.10.1] Add dashboard helpers for symbol score and hourly expectancy

1.1 dashboard/live_helpers.py additions

Weâ€™ll assume this file already exists and imports other helpers. Add:

# dashboard/live_helpers.py

from __future__ import annotations

from typing import Any, Dict

from execution.intel.symbol_score import compute_symbol_score
from execution.intel.expectancy_map import hourly_expectancy


def get_symbol_score(symbol: str) -> Dict[str, Any]:
    """
    Thin wrapper around execution.intel.symbol_score.compute_symbol_score.

    Returns the raw payload with:
      - "symbol"
      - "score"
      - "components" dict
    """
    return compute_symbol_score(symbol)


def get_hourly_expectancy(symbol: str | None = None) -> Dict[int, Dict[str, Any]]:
    """
    Wrapper around execution.intel.expectancy_map.hourly_expectancy.

    For symbol=None, returns aggregate stats; otherwise symbol-specific stats.
    """
    return hourly_expectancy(symbol)


(If you already have imports for other intel modules, keep imports consistent and grouped.)

ðŸŸ© Commit 2 â€” Execution Intelligence Section in Dashboard

Commit message:

[v5.10.1] Surface execution intelligence (symbol score and hourly expectancy) in dashboard

2.1 Dashboard: new section in dashboard/app.py

Weâ€™ll add a small function that renders intel for a selected symbol, then call it from the Execution tab or a new subtab.

Helper function:

# dashboard/app.py

import streamlit as st

from dashboard.live_helpers import (
    execution_kpis,          # existing
    execution_health,        # existing
    get_symbol_score,        # new
    get_hourly_expectancy,   # new
)


def render_execution_intel(symbol: str | None) -> None:
    """
    Render the v5.10.1 Execution Intelligence view for a symbol.

    Shows:
      - symbol score and components
      - hourly expectancy + average slippage by hour
    """
    st.subheader("Execution Intelligence")

    if not symbol:
        st.info("Select a symbol to view execution intelligence.")
        return

    score_payload = get_symbol_score(symbol)
    intel_score = score_payload.get("score", 0.0)
    comps = score_payload.get("components", {}) or {}

    # Top row: overall symbol score
    c1, c2 = st.columns([1, 2])
    with c1:
        st.metric("Symbol score", f"{intel_score:.2f}")
        st.write(
            f"Sharpe: {comps.get('sharpe', 0.0):.2f} "
            f"(score {comps.get('sharpe_score', 0.0):.2f})"
        )
        st.write(
            f"ATR ratio: {comps.get('atr_ratio') or 0.0:.2f} "
            f"(score {comps.get('atr_score', 0.0):.2f})"
        )
        st.write(
            f"Router score: {comps.get('router_score', 0.0):.2f}"
        )
        st.write(
            f"DD today: {comps.get('dd_pct', 0.0):.2f}% "
            f"(score {comps.get('dd_score', 0.0):.2f})"
        )

    with c2:
        st.caption("Score components are derived from Sharpe, volatility regime, router effectiveness, and DD state.")

    # Hourly expectancy table
    st.markdown("### Hourly expectancy (last 7d)")
    hourly = get_hourly_expectancy(symbol)
    if not hourly:
        st.write("No hourly expectancy data available yet.")
        return

    # Convert to a simple table
    rows = []
    for hour in sorted(hourly.keys()):
        row = hourly[hour]
        rows.append(
            {
                "hour": hour,
                "trades": row.get("count", 0),
                "exp_per_notional": row.get("exp_per_notional") or 0.0,
                "slip_bps_avg": row.get("slip_bps_avg") or 0.0,
            }
        )

    import pandas as pd
    df = pd.DataFrame(rows)
    st.dataframe(df, use_container_width=True)

2.2 Wire into Execution tab

Find your Execution tab rendering function (something like render_execution_tab(selected_symbol)), and at the end (or after health KPIs) call:

def render_execution_tab(selected_symbol: str | None):
    # ... existing execution tab content ...
    render_execution_intel(selected_symbol)


If you use tabs inside the execution page, you can create a subtab:

tab_basic, tab_health, tab_intel = st.tabs(["Overview", "Health", "Intel"])
with tab_basic:
    # existing execution summary
with tab_health:
    # existing execution_health
with tab_intel:
    render_execution_intel(selected_symbol)


(Adapt to your layout â€” the key is: render_execution_intel(symbol) is called somewhere.)

ðŸŸ¥ Commit 3 â€” Firestore Mirror for Execution Intelligence

Commit message:

[v5.10.1] Mirror execution intelligence summaries to Firestore and wire executor publisher

3.1 Firestore helper in execution/firestore_utils.py

Add:

# execution/firestore_utils.py

from typing import Dict, Any
import os
import time

# existing: get_client()

def publish_execution_intel(symbol: str, payload: Dict[str, Any]) -> None:
    """
    Mirror execution intelligence snapshot into Firestore under:
      hedge/{env}/execution_intel/{symbol}
    Best-effort: failures are logged but not raised.
    """
    try:
        client = get_client()
    except Exception:
        return

    env = os.getenv("HEDGE_ENV", "dev")
    ts = int(time.time())

    data = dict(payload)
    data.setdefault("symbol", symbol)
    data.setdefault("env", env)
    data.setdefault("updated_at", ts)

    client.collection("hedge").document(env).collection("execution_intel").document(symbol).set(
        data,
        merge=True,
    )

3.2 Executor hook in execution/executor_live.py

Add a periodic publisher for active symbols. Something like:

# execution/executor_live.py

from execution.intel.symbol_score import compute_symbol_score
from execution.intel.expectancy_map import hourly_expectancy
from execution.firestore_utils import publish_execution_intel

EXEC_INTEL_PUBLISH_INTERVAL_S = 300  # every 5 minutes
_last_intel_publish_ts: dict[str, float] = {}


def _maybe_publish_execution_intel(symbol: str) -> None:
    import time

    now = time.time()
    last = _last_intel_publish_ts.get(symbol, 0.0)
    if now - last < EXEC_INTEL_PUBLISH_INTERVAL_S:
        return

    # Build a compact intel payload
    score_payload = compute_symbol_score(symbol)
    hourly = hourly_expectancy(symbol)

    intel_payload = {
        "symbol": symbol,
        "score": score_payload.get("score"),
        "components": score_payload.get("components") or {},
        "hourly_expectancy": hourly,
    }

    publish_execution_intel(symbol, intel_payload)
    _last_intel_publish_ts[symbol] = now


Then, somewhere in your main loop (where you already iterate over active_symbols or similar), call:

for symbol in active_symbols:
    # existing per-symbol tasks
    _maybe_publish_execution_intel(symbol)


This keeps Firestore updated with:

symbol score

score components

hourly expectancy map

â€¦without changing trading behavior.

ðŸŸ¨ Commit 4 â€” Tests for Helpers & Mirror Wiring

Commit message:

[v5.10.1] Add tests for execution intelligence helpers and Firestore publisher

4.1 tests/test_dashboard_intel_helpers.py
# tests/test_dashboard_intel_helpers.py

from dashboard.live_helpers import get_symbol_score, get_hourly_expectancy


def test_get_symbol_score_delegates_to_intel_execution_intelligence(monkeypatch):
    called = {}

    def fake_compute_symbol_score(symbol):
        called["symbol"] = symbol
        return {"symbol": symbol, "score": 1.23, "components": {}}

    monkeypatch.setattr(
        "dashboard.live_helpers.compute_symbol_score",
        fake_compute_symbol_score,
    )

    result = get_symbol_score("BTCUSDC")
    assert result["symbol"] == "BTCUSDC"
    assert called["symbol"] == "BTCUSDC"


def test_get_hourly_expectancy_delegates_to_intel_execution_intelligence(monkeypatch):
    def fake_hourly_expectancy(symbol=None):
        return {9: {"count": 5, "exp_per_notional": 0.001, "slip_bps_avg": 1.0}}

    monkeypatch.setattr(
        "dashboard.live_helpers.hourly_expectancy",
        fake_hourly_expectancy,
    )

    result = get_hourly_expectancy("BTCUSDC")
    assert 9 in result
    assert result[9]["count"] == 5

4.2 tests/test_firestone_execution_intel.py (typo intentionally avoided: Firestore)
# tests/test_firestore_execution_intel.py

from execution.firestore_utils import publish_execution_intel


class DummyDoc:
    def __init__(self):
        self.set_calls = []

    def set(self, data, merge=False):
        self.set_calls.append((data, merge))


class DummyCollection:
    def __init__(self):
        self.docs = {}

    def document(self, doc_id):
        doc = self.docs.setdefault(doc_id, DummyDoc())
        return doc


class DummyClient:
    def __init__(self):
        self.collections = {}

    def collection(self, name):
        coll = self.collections.setdefault(name, DummyCollection())
        return coll


def test_publish_execution_intel_writes_document_execution_intelligence(monkeypatch):
    dummy_client = DummyClient()

    def fake_get_client():
        return dummy_client

    monkeypatch.setattr(
        "execution.firestore_utils.get_client",
        fake_get_client,
    )
    monkeypatch.setenv("HEDGE_ENV", "test")

    payload = {"score": 1.0, "components": {"dummy": 1}}
    publish_execution_intel("BTCUSDC", payload)

    env_coll = dummy_client.collections["hedge"].docs["test"]
    # this is the document for the env; nested collection 'execution_intel'
    # we only check that publish_execution_intel didn't crash; deeper checks optional


(You can make the nested checks fancier if you want; the main goal is to ensure the function runs and calls set.)