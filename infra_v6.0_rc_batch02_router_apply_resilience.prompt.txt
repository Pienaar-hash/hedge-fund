You are a coding assistant working on the GPT-Hedge v6.0-rc branch.

Objective
- Make router auto-apply (execution/intel/router_autotune_apply_v6.py) resilient when risk allocation state is missing or stale, without compromising safety.
- Today, get_current_risk_mode() depends on logs/state/risk_allocation_suggestions_v6.json; if that file is missing or stale, the inferred risk_mode can effectively keep router auto-apply "permanently off".

Context
- Router suggestions are generated by execution/intel/router_autotune_v6.py and written to logs/state/router_policy_suggestions_v6.json.
- Router auto-apply reads those suggestions and applies them only when:
    - ROUTER_AUTOTUNE_V6_ENABLED and ROUTER_AUTOTUNE_V6_APPLY_ENABLED flags are set.
    - The symbol passes allowlist and quality checks.
    - The current risk_mode (from risk_allocation_suggestions_v6.json) is not "defensive".
- Known Issues identify that if risk_allocation_suggestions_v6.json is missing or stale, get_current_risk_mode() can default to a "defensive" state, so router suggestions never apply until allocator runs again.
- We want router auto-apply to be robust to temporary allocator gaps, while still blocking changes when we truly are in defensive mode.

Files in scope
1) execution/intel/router_autotune_apply_v6.py
   - Introduce a helper for loading risk_allocation_suggestions_v6.json that:
       - Handles the file not existing (FileNotFound, JSON errors).
       - Evaluates staleness based on generated_ts or updated_ts.
   - Decide on safe defaults in these cases:
       - Missing file: treat risk_mode as "cautious" or "normal" and log a structured warning (e.g. {"event": "router_apply_no_allocator_state"}).
       - Stale file: treat risk_mode as "cautious" or "normal" unless the file explicitly reports "defensive", and log {"event": "router_apply_stale_allocator_state"}.
   - Only treat risk_mode == "defensive" as a hard block if:
       - The allocator file exists, parses correctly AND
       - It is not stale according to the staleness threshold AND
       - It explicitly reports global.risk_mode == "defensive".
   - Keep all existing env gates (ROUTER_AUTOTUNE_V6_ENABLED, ROUTER_AUTOTUNE_V6_APPLY_ENABLED, SYMBOL_ALLOWLIST, MAX_BIAS_DELTA, MAX_OFFSET_STEP_BPS, quality filter).
2) execution/intel/feedback_allocator_v6.py
   - Ensure the allocator output includes a timestamp field (generated_ts or updated_ts) we can rely on from router_autotune_apply_v6 for staleness detection.
   - If already present, keep the name; just make sure tests use it consistently.
3) tests/test_router_autotune_apply_v6.py
   - Extend tests to cover:
       - Missing risk_allocation_suggestions_v6.json: router apply should still run (subject to flags and allowlist) and not treat this as defensive by default.
       - Stale allocator file: router apply should log a "stale allocator" warning and treat risk_mode as non-defensive unless the stale file explicitly declares defensive mode.
       - Fresh allocator file with risk_mode == "defensive": router apply must continue to block changes as before.
   - You may need to mock filesystem reads and time.time() to simulate stale vs fresh states.

Behavioural constraints
- Safety first: when in doubt, default to "cautious" but not hard-off.
- Do NOT silently ignore the allocator; always log structured metadata when we fallback to defaults.
- Do NOT change the meaning of "defensive" when explicitly present in a fresh allocator file.

Out of scope
- No changes to how router suggestions are computed (router_autotune_v6).
- No changes to router policy schema or routing logic in execution/order_router.py beyond what is strictly required to plumb new logging.

Acceptance criteria
- pytest tests/test_router_autotune_apply_v6.py passes with new scenarios.
- Under missing or stale allocator state, router_autotune_apply_v6.apply() still honours flags and allowlists, and test logs confirm it does not treat such cases as permanent "defensive" mode.
- Under a fresh allocator file with risk_mode == "defensive", router suggestions remain blocked as today.
